{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72019194-a5b0-4d79-9bf1-0ffb682510a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from utils import sample_example_dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29731eca-050a-4f72-b313-7bd858aed2ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/rocabrera/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ea6a9454044081beb406224850491f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = load_dataset(\"squad\")\n",
    "train, validation = data[\"train\"], data[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdb904b-e978-4857-a3f0-13a6a9611a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_name: str):\n",
    "    \n",
    "    # One can use T5ForConditionalGeneration (or the Tensorflow/Flax variant), which includes the language modeling head on top of the decoder.\n",
    "    model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "    return model, tokenizer\n",
    "\n",
    "def tokenize_input(sample: dict):\n",
    "\n",
    "    encoding = tokenizer(\n",
    "        'question answering: ' + sample[\"question\"],\n",
    "        sample[\"context\"],\n",
    "        max_length=396,\n",
    "        padding=\"max_length\",\n",
    "        truncation=\"only_second\", # Se nao me engano trunca somente o contexto .... Problematico dependendo de onde a resposta esta\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return encoding\n",
    "\n",
    "def model_answer(model, inputs) -> str:\n",
    "    \n",
    "    generated_ids = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        num_beams=1,\n",
    "        repetition_penalty=2.5,\n",
    "        length_penalty=1.0\n",
    "    )\n",
    "\n",
    "    preds = [tokenizer.decode(generated_id, \n",
    "                              skip_special_tokens=True, \n",
    "                              clean_up_tokenization_spaces=True) \n",
    "             for generated_id in generated_ids]\n",
    "\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8932341-1447-497b-91e1-5f5eac0e11cc",
   "metadata": {},
   "source": [
    "# **Testing t5-base**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8ef69a-44dc-4004-965b-e5df93d247c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_models(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36227c72-2e3d-4545-914e-1fd1f277fdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mWhere is the headquarters of the Congregation of the Holy Cross?\u001b[0m\u001b[32mThe university is the major seat of the\n",
      "Congregation of Holy Cross (albeit not its official headquarters, which are in \u001b[0m\u001b[34mRome\u001b[0m\u001b[32m). Its main\n",
      "seminary, Moreau Seminary, is located on the campus across St. Joseph lake from the Main Building. Old College, the\n",
      "oldest building on campus and located near the shore of St. Mary lake, houses undergraduate seminarians. Retired priests\n",
      "and brothers reside in Fatima House (a former retreat center), Holy Cross House, as well as Columba Hall near the\n",
      "Grotto. The university through the Moreau Seminary has ties to theologian Frederick Buechner. While not Catholic,\n",
      "Buechner has praised writers from Notre Dame and Moreau Seminary created a Buechner Prize for Preaching.\u001b[0m\n",
      "\u001b[31mTRUE LABEL: Rome\u001b[0m\n",
      "\n",
      "Respsota do Modelo:\n",
      "Rome\n"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "_ = sample_example_dataset(train, idx)\n",
    "sample = train[idx]\n",
    "inputs = tokenize_input(sample)\n",
    "\n",
    "answer = model_answer(model, inputs)\n",
    "print(f\"\\nRespsota do Modelo:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54a33bc-fee8-42f2-8e35-5b9c6427c49e",
   "metadata": {},
   "source": [
    "# **Testing t5-large**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d3d08d-ef39-4f92-b96a-a7d84ac0dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_models(\"t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb616f4e-559b-4baf-a81a-a39451041fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "_ = sample_example_dataset(train, idx)\n",
    "sample = train[idx]\n",
    "inputs = tokenize_input(sample)\n",
    "\n",
    "answer = model_answer(model, inputs)\n",
    "print(f\"\\nRespsota do Modelo:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ed707-7d60-4258-8f95-30fa6088aa73",
   "metadata": {},
   "source": [
    "# **Testing t5-3b**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72c857-4611-455b-9106-b1e773346680",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = load_models(\"t5-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4a526-5b12-4a44-9e5a-7fd82f060db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "_ = sample_example_dataset(train, idx)\n",
    "sample = train[idx]\n",
    "inputs = tokenize_input(sample)\n",
    "\n",
    "answer = model_answer(model, inputs)\n",
    "print(f\"\\nRespsota do Modelo:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e2b01-ae9e-4bab-8ea0-82310719faab",
   "metadata": {},
   "source": [
    "# **Conclus√µes preliminares**\n",
    "\n",
    "t5-base consegue responder o dataset do squad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_huggingface",
   "language": "python",
   "name": "venv_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
